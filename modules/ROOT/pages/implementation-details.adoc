[id="implementation-details"]
= Implementation Details

Lookyloo is the glue that puts together and sometimes repurpose a bunch of tools
developed by others.

== Backend

=== Redis

link:https://redis.io/[Redis] is the database used to store the cached information visualized on the web interface.

=== Splash and scrapy

====
Splash is a javascript rendering service. It’s a lightweight web browser
with an HTTP API, implemented in Python 3 using Twisted and QT5. The (twisted)
QT reactor is used to make the service fully asynchronous allowing to take
advantage of webkit concurrency via QT main loop.
====
More on the link:https://splash.readthedocs.io/en/stable[official website]

In Lookyloo, splash loads a web page in a similar fashion a web browser does. When the
page is done loading, it scrolls down and wait a little bit longer.
When itś done, it returns an link:http://www.softwareishard.com/blog/har-12-spec/[HTTP Archive (HAR)],
the **page rendered at the end of the capture** (that would be the same as what you would see when
viewing the source of the page in your browser), a **screenshot of the whole page**,
**all the cookies** what were received and created during the capture, and the
**URL in the address bar** of the browser.

The capture is controled by a link:https://github.com/Lookyloo/ScrapySplashWrapper/blob/main/scrapysplashwrapper/crawl.lua[LUA script]

In order to extract information from the page and instrument the capture
itself, we use link:https://scrapy.org/[scrapy]:

====
Scrapy is a fast high-level web crawling and web scraping framework, used to crawl
websites and extract structured data from their pages. It can be used for a wide
range of purposes, from data mining to monitoring and automated testing.
====

With a lightweight connector called link:https://github.com/scrapy-plugins/scrapy-splash[scrapy-splash].

The whole system is bundled in an home-made standalone wrapper called link:https://github.com/Lookyloo/ScrapySplashWrapper[ScrapySplashWrapper].

=== ETE Toolkit & har2tree

The core feature of Lookyloo is the visualization of what is happenig in the browser
when you load a page. Our approach was to use a tree, and who does trees better than
researchers working in phylogenetics and genomics?

This is the reason we used link:http://etetoolkit.org/[ETE Toolkit]:

====
ETE (Environment for Tree Exploration) is a Python programming toolkit that assists
in the automated manipulation, analysis and visualization of phylogenetic trees.
Clustering trees or any other tree-like data structure are also supported.
====

And in order to create that tree, we use the HAR output generated by Splash, and pass
it to an other standalone library, link:https://github.com/Lookyloo/har2tree[har2tree].

We won't go in too many details regarding the process of building a tree out of a HAR file,
but you can read many comments link:https://github.com/Lookyloo/har2tree/blob/main/har2tree/parser.py[directly in the code].

== Frontend

=== D3JS

Initially, we used the link:https://github.com/etetoolkit/webplugin[webplugin] developed by ETE Toolkit,
but it turned out to be too limited for what we wanted to do, so instead of that,
we decided to use link:https://d3js.org/[d3js]:

====
D3.js is a JavaScript library for manipulating documents based on data. D3 helps
you bring data to life using HTML, SVG, and CSS. D3’s emphasis on web standards gives
you the full capabilities of modern browsers without tying yourself to a proprietary
framework, combining powerful visualization components and a data-driven approach to DOM manipulation.
====

And implemented a compatible json output into link:https://github.com/Lookyloo/har2tree/blob/cf0147ff1e1171870e2a62e3b5ec66c9b1c684c5/har2tree/parser.py#L392[har2tree].

=== Flask & Bootstrap

For the web interface, we used link:https://flask.palletsprojects.com/en/1.1.x/[Flask]
and link:https://getbootstrap.com/docs/4.5/getting-started/introduction/[bootstrap 4].

Everything related to the website is link:https://github.com/Lookyloo/lookyloo/tree/main/website[in a subdirectory]
in the link:https://github.com/Lookyloo/lookyloo[lookyloo repository].

== Modules and 3rd party components

In order to give more context about the URLs given by the users, we use some 3rd party services.
Some will be used to match received content with known ressources (JavaScript libraries, CSS, images), while
other will alow us to match requests with known malicious content.

=== SaneJS

It uses the link:https://cdnjs.com/[CDNJS] link:https://github.com/cdnjs/cdnjs[repository]
to build a hash database of a vast amount of resources used all over the internet.

The project is link:https://github.com/Lookyloo/sanejs[standalone] and can be used
outside of lookyloo (even if it was promarily developped for it) with a python client called
link:https://github.com/Lookyloo/pysanejs[pysanejs].

[NOTE]
We're not re-using the link:https://github.com/cdnjs/SRIs/blob/master/README.md[SRIs] for a pretty silly reason:
many resources used on websites are the same as the ones in CDNJS, but with an extra new line at the end of the file.
SaneJS computes hashes for every file with and without a newline, allowing us to match more resources.

=== Virus Total

link:https://www.virustotal.com[Virus Total] allows to submit and query URLs in their huge dataset.
Lookyloo will query do exactly that and inform the user if the know it is malicious.


=== Phishing Initiative

link:https://phishing-initiative.lu[Phishing Initiative] allows to submit and query URLs.
Lookyloo will query do exactly that and inform the user if the know it is malicious.

As it requires an API key, the feature isn enabled by default.

== Packaging

=== Poetry

In order to ease the de plyment of lookyloo, we use link:https://python-poetry.org/[poetry]:

====
Poetry helps you declare, manage and install dependencies of Python projects, ensuring you have the right stack everywhere.
====
